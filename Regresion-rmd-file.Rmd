---
title: "Modeling and prediction for movies"
output:
  word_document: default
  pdf_document: default
  html_document:
    author: "Varshit Dubey (COE PUNE)"
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
library(ggthemes)
library(corrgram)
library(corrplot)
library(caTools)
library(sp)
library(raster)
library(usdm)
library(lmtest)
```

* * *

### Load the data set


```{r}
# load the data set 
load("D:/Datasets/movies.Rdata")

```

***

## Part 1: Data

The data set is comprised of 651 randomly sampled movies produced and released before 2016.

Since random sampling is used in the collection of data set and no assignment is used ,this is an observational study, not experimental. 

We can only find correlation between variables and because of random sampling we can generalize the result to all the movies. We cannot find any causal relation as there is no random assignment(observational).


* * *

## Part 2: Research question

By looking at the data set the basic question which arises in mind is:

What makes the movie succesfull??

Which variables contributes to the critic's rating in the movie??

Does genre, audience score affects the critic's rating of rotten tomatoes(if particular genre movie has more chance of success)??

All this question can be addressed by linear modelling..

This research question will help to search for the factors that affects the score of critics, which factors to consider while making a review..

* * *

## Part 3: Exploratory data analysis

```{r}
# Explore the data set 
# Explore the first 10 observations
head(movies, 10)

tail(movies, 10)
```


```{r}
# explore the variables of movies data set
str(movies)

```


```{r}

# explore various statistical concepts of variables of movies data set
summary(movies)

```

Now we start to dig deeper in the data set.

```{r}


a3 <- movies %>% group_by(genre) %>% filter(!is.na(genre) , !is.na(imdb_rating)) %>% summarise(meanrating= mean(imdb_rating)) %>% arrange(desc(meanrating))

a3

```

This result shows movies with genre "Documentary " has the highest average rating in IMDB while comedy has the lowest average rating.

```{r}

# filtering the data according to the variables of interest.

a0 <- movies %>% group_by(genre) %>% filter(!is.na(genre), !is.na(critics_score)) %>% summarise(meancritic=mean(critics_score),meanaudience = mean(audience_score)) %>% mutate(diff = meanaudience- meancritic) %>% arrange(desc(diff))

a0
```

This table shows the average rating given by critics and audience based on genre. As you can see from the table there is difference in rating. So we can say that audience and critics and audience have different taste of movies.

```{r}
# average of difference between audience and critcs rating based on genre

movies %>% mutate(diff = audience_score - critics_score) %>% group_by(genre) %>% summarise(m = mean(diff)) %>% arrange(desc(m))

```


And the second table shows the differece in audience and  critics rating on rotten tomatoes.The above result shows that Audience tend to like  "Action and adventure" movies while Critics give them low ratings on average.


```{r, fig.width= 12, fig.height= 8}
# Looking at the data by some visualization..

ggplot(data= movies , aes(x= audience_score ,y= critics_score)) + 
  geom_point(size = 5) + geom_smooth(method= "lm",se= FALSE) + ggtitle("Plot of Audience vs Critic's Ratings") 

```

The above plot shows there is positive linear relation between audience and critic scores.
Let's make this plot more attractive.

```{r, fig.height= 8, fig.width= 12}

ggplot(data= movies , aes(x= audience_score ,y= critics_score)) + geom_point(mapping = aes(colour = genre), size = 5) + geom_smooth(method= "lm",se= FALSE) + ggtitle("Plot of Audience vs Critic's Ratings") +  
  theme_bw() + xlab("Audience Score") +ylab("Critics Score") + 
  theme(plot.title = element_text(size = 20, 
                                  face = "bold",
                                  hjust = 0.5))

```


```{r, fig.height= 12, fig.showtext= 5, dpi=100, fig.width= 15, out.height= "200px"}
mod_movies <- movies %>% filter(audience_score >= 50) 

ggplot(mod_movies, aes(critics_score, audience_score, color = genre)) + geom_point(aes(size = critics_rating), fill = 0.7) + geom_text(aes(label = ifelse(audience_score >= 50 & critics_score < 20, as.character(title),''),
                                                                                                                                           hjust = 0.5,vjust = -2), size = 6, face = "bold") + xlab("Critics Score") + 
  ylab("Audience Score more than 50")  + 
  ggtitle("Scatter plot between Audience and Critics Rating") +
  theme_bw(base_size = 20) + 
  theme(plot.title = element_text(size = 30, face = "bold", hjust = 0.5, colour = "Blue"), 
        axis.title.x = element_text(size = 20, colour = "Dark Green"), 
        axis.title.y = element_text(size = 20, colour = "Dark Green"))

```

I selected rows whose audience_score is more than 50 and stored the new data frame.

And I plot the scatterplot, between critics_score an audience_score, and also added size and colour to make it more beautiful. Ignore the warning.

Conclusion - Surely there are some movies whose critics_score is less than 20 but audience rated it more than 50. I highlighted these movies. Interesting.

Audience rated some movies even more than 80 while critics rated it less than even 25, for ex. see the movie "Rise of the Footsoldier".

Now we try to make a scatterplot which shows the plot based on individual levels of categorical variables, like a grid.

```{r, fig.width= 12, fig.height= 8}

ggplot(movies) + geom_point(mapping = aes(audience_score, critics_score)) + 
  facet_grid(mpaa_rating~genre) +
  labs(title = "Facet grid based on genre and Mpaa rating") + 
  theme_bw() + 
  theme(axis.title.x = element_text(size = 20, colour = "Red"), 
        axis.title.y = element_text(size = 20, colour = "Red"), 
        plot.title = element_text(size = 30, hjust = 0.5, colour = "Dark Blue", face = "bold"), 
        axis.title.x.top = element_text(size = 10))

```

Now let's try to make scatter plot with another variables..

```{r, fig.width=12, fig.height=8}

ggplot(data= movies, aes(x= imdb_num_votes, y = imdb_rating)) + 
  geom_point(aes(colour = genre), size = 3, alpha = 0.6) + 
  geom_jitter(aes(colour = genre)) + xlab("Imdb Number of votes") + 
  ggtitle("Plot showing relationship of Imdb rating with Imdb number of Votes")+ 
  ylab("Imdb Rating") + 
  theme_bw(base_size = 17)  + 
  theme(plot.title = element_text(hjust = 0.5, size = 20, colour = "Red"), 
        axis.title.x = element_text(size = 15, colour = "Brown"), 
        axis.title.y = element_text(size = 15, colour = "Brown"))

```

The plot is very dense for imdb_num_vote less than 125,000. Greater than 125,000 the points are very scattered. Also one can infer that if the Imdb number of votes is greater than 300,000 or 500,000, chances are that the Imdb rating of that movie is greater than 7.5 or 8, so greater is the no. of votes more is the imdb_rating.

```{r, fig.width= 15, fig.height= 15}

movies %>% 
  mutate(diff = audience_score - critics_score) %>% 
  ggplot(aes(genre,diff))  + 
  geom_jitter(aes(colour = mpaa_rating,size = critics_rating)) + 
  geom_boxplot(aes(fill = genre, alpha = 0.1),show.legend = F,outlier.shape = NA) + 
  theme_bw(base_size = 30) + labs(y = "Difference in Audience and Critics", x = "Genre", title = "Boxplot of difference in audience and critics rating") + 
  theme(plot.title = element_text(size = 30, face = "bold", hjust = 0.5, colour = "Dark Green"), 
        axis.title.x = element_text(size = 30, colour = "Red"), 
        axis.title.y = element_text(size = 30, colour = "Red"), 
        axis.text.x = element_text(angle = 45, colour = "Blue", hjust = 1, size = 20), 
        legend.key.size = unit(2,"line"), 
        legend.title = element_text(colour = "blue", face = "bold"),
        legend.text = element_text(face = "bold"))

```

The above boxplot shows the distribution of observations of difference in audience and critics score, based on different genres. We can see that audience tend to score the movie more than critics for most of the genre as their the median of many boxplots is more than 0, but for some genres like "Documentary" the median is less than 0, means critics tend to score more than audience in this case.

```{r}
# Now we find correlation coefficient between all the numeric variables of the data set.

# Removing missing values

dat <- movies %>% 
  filter(!is.na(runtime), !is.na(dvd_rel_day), !is.na(dvd_rel_month), !is.na(dvd_rel_year))

# Grab only numeric columns
num.cols <- sapply(dat, is.numeric)

# Filter to numeric columns for correlation
cor.data <- cor(dat[,num.cols])

cor.data

```


```{r, fig.width= 10, fig.height= 8}

# Making correlation plot


corrgram(movies, order=TRUE, main="Movies data set",
         lower.panel=corrgram::panel.ellipse,
         upper.panel=panel.pie, diag.panel=panel.density,
         col.regions=colorRampPalette(c("darkgoldenrod4", "burlywood1",
                                        "darkkhaki", "darkgreen")))

```

The plot shown in the figure visualises the big correlation table we made, now it becomes easier to make conclusions regarding which variables are more correlated to each other and which are not as it is difficult to make conclusions based on just observing the correlation matrix. The more a box is blue, more correlated are the 2 variables which made that box. As expected, audience score, critics_score, imdb_rating, are somewhat more correlated to each other than the rest.


Now we make a histogram of imdb rating of movies and see the type of distribution.

```{r, fig.width= 12, fig.height= 8}

ggplot(data = movies, aes(x = imdb_rating)) + 
  geom_histogram(mapping = aes(fill = genre), colour = "black", binwidth = 1) + 
  theme_bw() + 
  labs(title = "Histogram of IMDB rating of Movies", x = "IMDB Rating", y = "Count") + 
  theme(plot.title = element_text(size = 20, face = "bold", color = "Brown", hjust = 0.5), 
        axis.title.x = element_text(face = "bold", color = "Blue", size = 15), 
        axis.title.y = element_text(face = "bold", color = "blue", size = 15))

```

In this histogram we also segregated the count by different genre, like in a range of imdb_rating, which genre has how many movie. We can see that the distribution of imdb_rating is slightly left skewed.

Now let's see another visual..

```{r, fig.width= 15, fig.height= 8}

ggplot(movies, aes(mpaa_rating)) +  
  geom_bar(aes(fill = genre), color = "black", position = "dodge") + 
  labs(title = "Bar Plot of Mpaa rating", y = "Count", x = "Mpaa rating") +  
  theme_bw(base_size = 15) + 
  theme(plot.title = element_text(hjust = 0.5, size = 25, face = "bold", color = "Dark Blue"), 
        axis.title.x = element_text(size = 20, face = "bold", colour = "Brown"), 
        axis.title.y = element_text(size = 20, face = "bold", colour = "Brown"), 
        axis.text.x = element_text(size = 20, colour = "Dark Green"), 
        legend.title = element_text(colour = "Purple", size = 15), 
        legend.text = element_text(size = 15, colour = "Blue")) 

```

This bar plot shows count of various mpaa rating of movies with genre, one can see from the graph that "Horrer" movies are mostly rated "R", most of the movies in our data set are "R" rated, with "G" category the least. 


* * *

## Part 4: Modeling


To make a model, I am going to predict the critcs score of rotten tomatoes. 

I am not using the variables "actor1" to "actor5" as they are statistically insignificant variables, also I am not adding release date variables as they are also statistically insignificant variables. Though I think year and month can have significant role to play in the model as this data set contains information of movies as old as 1970's and I think there is a steady transformation in the critic score and their thinking for a movie from 1970 to 2016. 

I am not including "title" as the movie title name is of no use, also I removed "studio", though it can have some effect on our model, but there are 211 studio in our data set, some studio has 1 or 2 movies some have even more than 30, it will only add confusion to our model, so I removed studio variable. You can add studio in your model if you want.


```{r}
# data preprocessing step
# Removing some variables which are statistically insignificant.
class(movies)

mod_data <- movies[,-c(25:32)]
mod_data <- mod_data[,-c(1,6,9,12)]

# Removing or replacing Missing values
mod_data$runtime <- ifelse(is.na(mod_data$runtime), mean(mod_data$runtime, na.rm = T), mod_data$runtime)

mod_data <- mod_data %>% filter(!is.na(dvd_rel_year), !is.na(dvd_rel_month))

# Dividing the data into training and test set

# set.seed(123)
# split = sample.split(mod_data$critics_score, SplitRatio = 0.70)
# training_set = subset(mod_data,split == T)
# test_set = subset(mod_data, split == F)

# checking vif for all numeric values..

mod_data1 <- select_if(mod_data, is.numeric)

vif(data.frame(mod_data1[,-8]))


```

Now I will make the model for all the available variables in the modified data set..

```{r}

m1 <- lm(critics_score~., data = mod_data)
summary(m1)

```

Well there are many insignificant variables in the data set..
There are many approaches to get to the final solution, like using step, chacking p value, Adjusted R- Squared method, checking vif.
First, I'm gonna use step function to find the final set of variables in our final model..

```{r}

m2 <- step(m1)
summary(m2)

# checking vif for the variables in the final model..
vif(data.frame(mod_data[,c("thtr_rel_year","imdb_rating","imdb_num_votes")]))

```

Our vif is in acceptable range.
So using step function our initial model with 20 variables gets reduced to only 5 variables.

Now we will use backward elimination to find the final equation..



First of all, I am going to add all the variables in the model and use backward elimination to make the final model. I am going to do backward elimination by 'Adjusted R squared technique' as I think this method gives good robust results and also I look at p- values of variables in the model to do backward elimination, the significance level will be 0.05 for p-value.


```{r}

#assumed model

m1 <- lm(critics_score ~. , data= mod_data)

summary(m1)


```

Now comparing p-value of all variables in the model, we see that "best_pic_win" variable has the highest p-value, so we will remove the variable.

```{r}
# without best_pic_win

m2 <- lm(critics_score ~. -best_pic_win, data= mod_data)

summary(m2)

# checking vif for the numeric variables..
mod_data2 <- select_if(mod_data, is.numeric)

vif(data.frame(mod_data2[,-8]))

```

We see that in our model now the adjusted R squared value is increased a bit, which is what we want, now looking at the model again we find that "best_actor_win" has the highest p-value now, so we will remove the variable.

```{r}
# without audience_score..

m3 <- lm(critics_score ~. -best_pic_win -best_actor_win, data= mod_data)

summary(m3)


```

Looking again at the model we will remove "audience_score" variable as it's p-value is highest and also the vif of audience_score is high, so there will be multicollinearity problems.

```{r}
# audience_score variable..

m4 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win-audience_score, 
    data = mod_data)

summary(m4)

# checking vif..
mod_data2 <- select_if(mod_data, is.numeric)
vif(data.frame(mod_data2[,c(-8,-9)]))

```

Now we can see that vif are all within considerable range after removing audience_score variable..

We will remove "runtime" variable as it's p-value is highest.

```{r}
# removing runtime variable

m5 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win-audience_score-runtime, 
    data = mod_data)

summary(m5)

```

Now we will remove "mpaa_rating" variable as p-value is very high.

```{r}
# without genre 

m6 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating, data = mod_data)

summary(m6)


```

But we see that even though we removed mpaa_rating variable our Adjusted R Squared value is reduced, but it is reduced by a very small amount by 0.0004 so it doesn't affect the model very much. Now we remove "audience_rating" variable.

```{r}
# without audience_rating..

m7 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating, data = mod_data)

summary(m7)

```

Now we will remove "dvd_rel_month" variable.

```{r}
# without dvd_rel_month variable.

m9 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating-dvd_rel_month, data = mod_data)

summary(m9)


```

Now we will remove "thtr_rel_month"..

```{r}
# Without thtr_rel_month variable

m10 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating-dvd_rel_month-thtr_rel_month, data = mod_data)

summary(m10)

```


Removing "best_pic_nom" variable..

```{r}
# removing best_pic_nom variable

m11 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating-dvd_rel_month-thtr_rel_month-best_pic_nom, data = mod_data)

summary(m11)

```

Now we will remove "best_dir_win". 

```{r}
# removing thtr_rel_month
m12 <-lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating-dvd_rel_month-thtr_rel_month-best_pic_nom-best_dir_win, data = mod_data)

summary(m12)

```

 Now Removing "top200_box" variable.

```{r}

m13 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating-dvd_rel_month-thtr_rel_month-best_pic_nom-best_dir_win-top200_box, data = mod_data)

summary(m13)

```

Now removing "best_actress_win" variable.

```{r}
m14 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating-dvd_rel_month-thtr_rel_month-best_pic_nom-best_dir_win-top200_box-best_actress_win, data = mod_data)

summary(m14)

vif(data.frame(mod_data2[,c("thtr_rel_year","dvd_rel_year","imdb_rating","imdb_num_votes")]))

```

Now removing "dvd_rel_year" variable..

```{r}
# removing dvd_rel_yearvariable..

m15 <- lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating-dvd_rel_month-thtr_rel_month-best_pic_nom-best_dir_win-top200_box-best_actress_win-dvd_rel_year, data = mod_data)

summary(m15)

```

Removing "genre"..

```{r}

m16 <-  lm(formula = critics_score ~ . - best_pic_win - best_actor_win - 
    audience_score - runtime - mpaa_rating-audience_rating-dvd_rel_month-thtr_rel_month-best_pic_nom-best_dir_win-top200_box-best_actress_win-dvd_rel_year-genre, data = mod_data)

summary(m16)

```

We see that our Adjusted R squared values decreses by small value that is 0.0003 so we will remove genre from our model as it is not adding significant to our regression model..

```{r}
# Our final model..

final <- lm(critics_score~title_type+thtr_rel_year+imdb_rating+imdb_num_votes+critics_rating,
            data = mod_data)
summary(final)

```


## Part 5 - Cross Validation

We will see how our existing model works on new data. 
What we will do is divide the data into training and test data, we will build model around training data and see the performance on test set..

```{r}
# Dividing the data into training and test set

 set.seed(123)
split = sample.split(mod_data$critics_score, SplitRatio = 0.70)
training_set = subset(mod_data,split == T)
test_set = subset(mod_data, split == F)

```

Now I decided to give 70% of the data to training and remaining 30% to the test set.

```{r}

final_train <- lm(critics_score~title_type+thtr_rel_year+imdb_rating+imdb_num_votes+critics_rating,
            data = training_set)
summary(final_train)

```

The summary is good, now let's check this on our test data..

```{r}

fitted <- predict(final_train, test_set)

```


Now let's check the efficiency of the model on test set...

```{r}
deviation <- test_set$critics_score-fitted ## deviation

per_deviation <- (test_set$critics_score-fitted)/test_set$critics_score  ##% deviation

abs_deviation <- abs(test_set$critics_score-fitted)/test_set$critics_score ##absolute deviation

mean(abs(test_set$critics_score-fitted)/test_set$critics_score) ##Mean abs % error
#MAPE - mean absolute percentage deviation

```


The value of MAPE is 0.34 which is not big, this can be reduced by using other methods, so we can say that our model is good. But we cannot stop here. For making a regression model we always make make some assumptions. We need to check that the assumptions are fulfilled.


## Part 6 - Interpretations of model coefficients:

Consider the intercept in the final model. This shows that if a documentary movie which does not show it's release year, it's Imdb rating, imdb number of votes and it is being rated by Certified fresh, the critics rating will be 411 which is vague and not possible.

For categorical variables like "title_type" and "critics_rating", one level of the variable is kept 0 which means that the level which is made 0. And the interpretation of other levels is made in reference to the factor made 0.

Considering the theatre release year variables, we can interpret that keeping rest of the variables constant, for a unit increase in year the critic score of rotten tomatoes decreases by about-1.924.

Consider the imdb_num_votes variables,  keeping rest of the variables constant, for unit increase in IMDB voters the critic rating is likely to decrease by 1.302e-05, which is vey small.  

## Part 7 - Model Diagnostics:

So we made our model. Now we check conditions required for multiple regression to be mapped valid.

1. The first condition is the linear relationship between numerical x and response variable. We can check this using residual plot with x variable(numerical).

```{r}

plot(final)

```


From Residuals vs fitted values we can see that the data point 44 is very influential, we can see the effect more clearly by plotting the histogram..

```{r}
res <- residuals(final)
res <- as.data.frame(res)
ggplot(res,aes(res)) +  geom_histogram(fill='blue',alpha=0.7, binwidth = 3) + xlab("Residuals") + ggtitle("Histogram Of Residuals") + theme_bw() + theme(plot.title = element_text(hjust = 0.5, colour = "Brown", face = "bold"))

```

Our residual plot becomes left skewed by some points as shown in the plot.
We will remove the data point at 44 and 458 as they are not influential also..

```{r}
mod_data5 <- mod_data[c(-44,-458),]
# I have removed some data points by checking the plots previously
mod_data6 <- mod_data5[c(-80,-77),]


final1 <- lm(critics_score~thtr_rel_year+ title_type+imdb_rating+imdb_num_votes+critics_rating,
            data = mod_data6[c(-57,-419),])

plot(final1)
res <- residuals(final1)
res <- as.data.frame(res)
ggplot(res,aes(res)) +  geom_histogram(fill='blue',alpha=0.7, binwidth = 3) + xlab("Residuals") + ggtitle("Histogram Of Residuals") + theme_bw() + theme(plot.title = element_text(hjust = 0.5, colour = "Brown", face = "bold"))

```

1. Now we by seeing different plots we can see that residuals and fitted values plot has values has a random scatter except between 45 to 55 as my model do not predict the values between the given interval, so we can say that our model is somewhat homoscedasticity..

2. Looking at the Normal Q-Q 
So we can see there is random scatter around 0, and by plotting histogram of residuals we see that the distribution is normally distributed centered around mean..

The plot between fitted and standardised residual is same except, here the residuals are standardized, and the plot is random which is good for our model..

3. The residuals vs levarage shows the data points from which our model affects significantly..

There is one criteria called cooks distance from which we can find the data point which is very influential..

The data point having cooks distance greater than 0.8 should be removed from our model..

```{r}
# plotting cooks distance
cook = cooks.distance(final1)
plot(cook,ylab="Cooks distances")

```


We can see that the cooks distance for all data points is very low, so we dont need to remove any data point from our model.

4. Now we check for autocorrelation in the observations..
There are many ways to check it, for example making Auto correlation plot, by durbin watson test or by using runs.test.

I am using durbin watson test for making  inference..

```{r}
# we will need lmtest package for it...

dwtest(final1)


```

The hypothesis are :
Null - True autocorrelation is 0.
Alternative - True autocorrelation is greater than 0.

Since the p-value is very high than 0.05 so we fail to reject the null hypothesis..

```{r}
plot(final1$residuals)

```


From this we check that the residuals are randomly scattered so we can say that there is no autocorrelation.

5. Multicollinearity - There may be a possibility that the predictor variables are themselves correlated among themselves, this will be a problem as our model will be added with unnecessary redundancies. This can be handled by checking vif. We have already checked vif for our variables, I am showing it once again for the sake of completing this assumptions section. The vif greater than 4 is undesirable..

```{r}

vif(data.frame(mod_data6[c(-57,-419),c("thtr_rel_year","title_type", "imdb_num_votes","imdb_rating","critics_rating")]))

```

As title_type and critics_rating are categorical variables, we compute vif only for numeric values, so there is NA in the output. As we can see the vif is less than 4 for all the numeric predictors, so we can say that there is no problem of multicollinearity.

* * *

## Part 7 - Let's check our model on any movie

Let's see the maximum value predicted by model.

```{r}
# Maximum value of prediction 
max(final1$fitted.values)

```

But when we look at the maximum value of our prediction, we see that it is 103.2646, we know that rotten tomatoes maximum score is 100. So we need to add certain restriction to our model so that our prediction doesn't exceeds 100. We can do it by making simple fucntion.

```{r}
predict_values <- data.frame(final1$fitted.values)
colnames(predict_values) <- c("Predict")
greater_hundred <- function(x){
    if  (x > 100){
        return(100)
    }else{
        return(x)
    }
}

predict_values$Predict <- sapply(predict_values$Predict, greater_hundred)
max(predict_values$Predict)

```

Now I'm going to predict the rotten tomatoes rating of one of my favourite movie of 2016 "Deadpool".

and regarding imdb_num_votes can be found at http://www.imdb.com/title/tt1431045/ratings?ref_=tt_ov_rt

dvd is released on May 2016,can be found by clicking this link https://www.imdb.com/title/tt1431045/?ref_=tt_rt

Deadpool is certified fresh which can be found on https://www.rottentomatoes.com/m/deadpool/ 

Now we have information regarding all the variables needed to make our model, we will put all in a data frame,

```{r}
# Taking information from a particualar movie which is not in the data set..

newmovie <- data.frame(thtr_rel_year = 2016, title_type = "Feature Film", imdb_rating = 8, imdb_num_votes = 747563, critics_rating = "Certified Fresh")

```

Now let's see what our model predicts.

```{r}
# predicting the value of critics score for the newmovie..

predict(final1, newmovie)

```

So our predicted value for rotten tomatoes critics rating is 81.66647 while the actual critic score which is available on rotten romatoes site is 83 as given on the site. So we can say that our model can approximately predicts the critic score of rotten tomatoes.


We can also construct a prediction interval around this prediction, which will
provide a measure of uncertainty around the prediction.

```{r}
#predicting newmovie confidence interval for the value of critics score..

predict(final1, newmovie, interval = "confidence", level = 0.95)

```

The above statement says that "We are 95% confident that the movie  "DEADPOOL"  will get critics score on average between 76.4622 and 86.87074 by Rotten tomatoes."


* * *

## Part 6: Conclusion

Thus we have found the factors which decides the success of the movie,like Imdb Rating, title type etc,  but we need more parameters(variables) to make more accurate prediction of the review as for now we can only approximate our findings based on the variables given in the data set. Like say "Box Office" and "Budget" can also play a very important role in predicting the crtics score of movie, like wise there are many.

The model can be used to predict the success rate of movie and by adding some input variables in the data set we can improve the performance of the model. 

